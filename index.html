<!DOCTYPE html>
<html lang="en-US">
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Do LLMs Have Personality? | CSCI 5541 (Spring 2025)</title>

  <!-- local CSS files are in the same folder -->
  <link rel="stylesheet" href="bulma.min.css">
  <link rel="stylesheet" href="styles.css">

  <style>
    img.responsive { max-width: 100%; height: auto; }
    h2            { margin-top: 2rem; }
    /* add a little space so the last section isn’t flush with the bottom edge */
    body          { padding-bottom: 3rem; }
  </style>
</head>

<body>
  <div class="wrapper">
    <h1 class="title">Do LLMs Have Personality?</h1>
    <h4 class="subtitle">CSCI 5541 – Natural Language Processing • University of Minnesota</h4>
    <h4 class="subtitle">Team “nvidia and chill”</h4>

    <hr>

    <!-- ABSTRACT -->
    <section id="abstract">
      <h2>Abstract</h2>
      <p>
        We administer the 30-item <em>BFI-2-S</em> to four instruction-tuned LLMs across 540
        synthetic demographic profiles. Over 64 000 responses reveal stable, model-specific
        personality signatures: Gemma is highly agreeable and emotionally stable, while LLaMA
        remains neutral. The study highlights the need for personality-aware evaluation when
        deploying conversational AI.
      </p>
    </section>

    <hr>

    <!-- INTRODUCTION -->
    <section id="introduction">
      <h2>1  Introduction & Motivation</h2>
      <p>
        LLMs often project a perceived “personality.” Such traits influence user trust and
        engagement, yet are seldom measured systematically. We quantify these latent tendencies
        with a standard psychometric test under controlled demographic prompts.
      </p>
    </section>

    <hr>

    <!-- METHODOLOGY -->
    <section id="methodology">
      <h2>2  Methodology</h2>

      <h3>2.1 Synthetic Profile Grid</h3>
      <ul>
        <li><strong>Age (6):</strong> 18–25 … 66+</li>
        <li><strong>Gender (3):</strong> Male, Female, Non-binary</li>
        <li><strong>Location (6):</strong> USA, Germany, India, Brazil, Japan, Australia</li>
        <li><strong>Education (5):</strong> High-School → Doctorate</li>
      </ul>

      <h3>2.2 Prompt Template</h3>
      <figure>
        <img src="bfi-2.png" class="responsive" alt="Prompt template">
        <figcaption style="text-align:center">
          Figure 1 – Example prompt containing demographics, instructions, and one BFI-2-S item.
        </figcaption>
      </figure>

      <h3>2.3 Inference & Scoring</h3>
      <p>
        Each model answered 16 200 prompts using deterministic decoding. Ratings were parsed,
        reverse-scored where needed, and averaged to trait means ± SD.
      </p>
    </section>

    <hr>

    <!-- RESULTS -->
    <section id="results">
      <h2>3  Results</h2>

      <h3>3.1 Trait Means</h3>
      <table class="table is-striped is-fullwidth">
        <thead>
          <tr><th>Model</th><th>Extr.</th><th>Agree.</th><th>Consc.</th><th>Neur.</th><th>Open.</th></tr>
        </thead>
        <tbody>
          <tr><td>Gemma-3-1B-it</td><td>4.19</td><td>4.60</td><td>4.40</td><td>1.89</td><td>4.20</td></tr>
          <tr><td>Qwen-2.5-3B </td><td>3.75</td><td>4.05</td><td>3.90</td><td>2.60</td><td>4.00</td></tr>
          <tr><td>LLaMA-3.2-1B</td><td>3.45</td><td>3.50</td><td>3.40</td><td>3.35</td><td>3.60</td></tr>
          <tr><td>LLaMA-3.2-3B</td><td>3.42</td><td>3.55</td><td>3.48</td><td>3.30</td><td>3.55</td></tr>
        </tbody>
      </table>

      <h3>3.2 Bar-Chart Comparison</h3>
      <figure>
        <img src="traits_across_models.png" class="responsive" alt="Trait comparison bar chart">
        <figcaption style="text-align:center">
          Figure 2 – Gemma is the most agreeable and least neurotic; LLaMA models cluster near
          neutral; Qwen sits between them for most traits.
        </figcaption>
      </figure>

      <p>
        <strong>Key observation:</strong> Gemma’s Agreeableness (4.60) and low Neuroticism (1.89)
        suggest a consistently supportive tone, while LLaMA’s near-midpoint scores imply a more
        balanced style. The differences persist across all demographics, indicating architecture
        and training data—not prompt wording—drive these personalities.
      </p>
    </section>

    <hr>

    <!-- CONCLUSION -->
    <section id="conclusion">
      <h2>4  Conclusion &amp; Future Work</h2>
      <p>
        Instruction-tuned LLMs exhibit measurable, model-specific personality biases. Selecting a
        model therefore means choosing—as well as aligning—a particular conversational style.
        Gemma may excel in empathetic roles; LLaMA’s neutrality might fit analytical tasks.
      </p>
      <p>
        <strong>Next steps:</strong> calibrate with human baselines, investigate prompt-level
        personality control, and develop mitigation strategies for demographic-linked bias.
      </p>
    </section>
  </div>
</body>
</html>
